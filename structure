explainable-rag-chatbot/
├── app/
│   ├── __init__.py
│   ├── main.py                  # FastAPI app entry point
│   ├── api/
│   │   ├── __init__.py
│   │   └── routes.py            # All endpoints
│   ├── core/
│   │   ├── __init__.py
│   │   └── config.py            # All settings from .env
│   ├── services/
│   │   ├── __init__.py
│   │   ├── document_processor.py # PDF/TXT → text extraction + chunking + upsert to Pinecone
│   │   ├── embedding_service.py  # OpenAI embeddings API wrapper
│   │   ├── pinecone_service.py   # Pinecone init + upsert + query
│   │   ├── llm_service.py        # OpenAI GPT generation + prompts
│   │   ├── rag_pipeline.py       # Full RAG flow: retrieve → verify → generate → explain
│   │   └── verification.py       # Claim verification + confidence scoring
│   ├── models/
│   │   ├── __init__.py
│   │   └── schemas.py            # Pydantic request/response models
│   ├── database/
│   │   ├── __init__.py
│   │   └── db.py                 # SQLite for chat history & document metadata
│   └── utils/
│       ├── __init__.py
│       └── helpers.py            # Chunking logic, text cleaning, etc.
├── data/
│   ├── uploads/                  # Temporary storage for uploaded files
│   └── sqlite.db                 # Chat history & document metadata
├── .env                          # All keys and config values
├── .env.example
├── requirements.txt
├── README.md
└── run.sh                        # Optional start script